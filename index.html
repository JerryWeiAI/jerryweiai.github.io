<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jerry Wei</title>
  
  <meta name="author" content="Jerry Wei">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jerry Wei</name>
              </p>
              <p>I am a Student Researcher at Google DeepMind and an undergraduate at Stanford University specializing in AI. In 2022, I interned at Meta. In 2019, I gave a spotlight talk at the Machine Learning for Health Workshop at NeurIPS (<a href="https://slideslive.com/38923239?time=1095">video</a>).
              </p>
              <p style="text-align:center">
                <a href="mailto:jerrywei@stanford.edu">Email</a> &nbsp/&nbsp
                <a href="data/Jerry_Wei___Research___Resume.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Y4sk3aMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
<!-- 	        <a href="http://arxiv.org/a/wei_j_3">arXiv</a> &nbsp/&nbsp -->
	        <a href="https://twitter.com/JerryWeiAI">Twitter</a>
<!--                 <a href="https://www.linkedin.com/in/jerrywwei/">LinkedIn</a> &nbsp/&nbsp -->
<!--    	        <a href="https://medium.com/@jerry-wei">Medium</a>  -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JW_ProfilePic.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/JW_ProfilePic.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Publications <a href="https://scholar.google.com/citations?user=Y4sk3aMAAAAJ&hl=en">(see all)</a></heading>
              <p>
                My recent research has focused on large language models, specifically the mechanisms that they use to perform in-context learning and how to improve their in-context learning abilities via finetuning.
              </p>
            </td>
          </tr>
        </tbody></table>
	      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		
	  <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
            	<a href="https://arxiv.org/abs/2305.08298">
                	<papertitle>Symbol tuning improves in-context learning in language models</papertitle>
                </a>
                <br>
                	<strong>Jerry Wei</strong>, 
		        Le Hou,
		    	Andrew Lampinen,
		    	Xiangning Chen,
		    	Da Huang,
		    	Yi Tay,
		    	Xinyun Chen,
		    	Yifeng Lu,
		    	Denny Zhou,
		    	Tengyu Ma,
		    	Quoc V. Le
                <br>
              		<em>arXiv</em>, 2023 &nbsp
                <br>
                <a href="https://arxiv.org/abs/2305.08298">arXiv</a>
            </td>
          </tr>
		
	  <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
            	<a href="https://arxiv.org/abs/2303.03846">
                	<papertitle>Larger language models do in-context learning differently</papertitle>
                </a>
                <br>
                	<strong>Jerry Wei</strong>, 
		        Jason Wei, 
		        Yi Tay, 
		        Dustin Tran, 
		        Albert Webson, 
		        Yifeng Lu, 
		        Xinyun Chen, 
		        Hanxiao Liu, 
		        Da Huang, 
		        Denny Zhou, 
		        Tengyu Ma
                <br>
              		<em>arXiv</em>, 2023 &nbsp
                <br>
                <a href="https://arxiv.org/abs/2303.03846">arXiv</a> / 
		<a href="https://ai.googleblog.com/2023/05/larger-language-models-do-in-context.html">Google AI Blog</a>
            </td>
          </tr>
	
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
            	<a href="https://arxiv.org/abs/1910.05827">
                	<papertitle>Generative image translation for data augmentation in colorectal histopathology images</papertitle>
                </a>
                <br>
                	<strong>Jerry Wei</strong>, 
		        Arief Suriawinata, 
		        Louis Vaickus, 
		        Bing Ren,
		        Xiaoying Liu, 
		        Jason Wei, 
		        Saeed Hassanpour
                <br>
              		<em>ML4H Workshop at NeurIPS</em>, 2019 &nbsp <font color="purple"><strong>(Spotlight Presentation)</strong></font>
                <br>
                <a href="https://arxiv.org/abs/1910.05827">arXiv</a> /
                <a href="https://slideslive.com/38923239?time=1095">Video</a>
            </td>
	</tr>

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
		      Original design and code derived from <a href="https://github.com/jonbarron/website">Jon Barron's website</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
